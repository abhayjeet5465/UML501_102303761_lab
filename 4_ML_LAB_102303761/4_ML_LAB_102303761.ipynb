{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed2e2536",
   "metadata": {},
   "source": [
    "                                                           ML LAB ASSIGNMENT 4\n",
    "                                                   SUBMITTED BY : ABHAYJEET(102303761)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de6667f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete! Saved as books.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "books = []\n",
    "\n",
    "page = 1\n",
    "while True:\n",
    "    url = base_url.format(page)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        break  # Stop if page not found\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "\n",
    "    if not articles:\n",
    "        break  # No more books\n",
    "\n",
    "    for book in articles:\n",
    "        title = book.h3.a[\"title\"]\n",
    "        price = book.find(\"p\", class_=\"price_color\").text.strip()\n",
    "        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "        star_rating = book.p[\"class\"][1] \n",
    "        books.append([title, price, availability, star_rating])\n",
    "\n",
    "    page += 1\n",
    "\n",
    "# Save to CSV\n",
    "df_books = pd.DataFrame(books, columns=[\"Title\", \"Price\", \"Availability\", \"Star Rating\"])\n",
    "df_books.to_csv(\"books.csv\", index=False)\n",
    "print(\"Scraping complete! Saved as books.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "276623bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete! Saved as imdb_top250.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top/\"\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "movies = []\n",
    "rows = driver.find_elements(By.CSS_SELECTOR, \"tbody.lister-list tr\")\n",
    "\n",
    "for row in rows:\n",
    "    rank = row.find_element(By.CSS_SELECTOR, \".titleColumn\").text.split(\".\")[0]\n",
    "    title = row.find_element(By.CSS_SELECTOR, \".titleColumn a\").text\n",
    "    year = row.find_element(By.CSS_SELECTOR, \".titleColumn span\").text.strip(\"()\")\n",
    "    rating = row.find_element(By.CSS_SELECTOR, \".imdbRating strong\").text\n",
    "\n",
    "    movies.append([rank, title, year, rating])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "df_movies = pd.DataFrame(movies, columns=[\"Rank\", \"Title\", \"Year\", \"IMDB Rating\"])\n",
    "df_movies.to_csv(\"imdb_top250.csv\", index=False)\n",
    "print(\"Scraping complete! Saved as imdb_top250.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "874edeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete! Saved as weather.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.timeanddate.com/weather/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "cities = []\n",
    "table = soup.find(\"table\", class_=\"zebra fw tb-theme\")\n",
    "\n",
    "for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) >= 3:\n",
    "        city_name = cols[0].text.strip()\n",
    "        temperature = cols[1].text.strip()\n",
    "        condition = cols[2].text.strip()\n",
    "        cities.append([city_name, temperature, condition])\n",
    "\n",
    "# Save to CSV\n",
    "df_weather = pd.DataFrame(cities, columns=[\"City\", \"Temperature\", \"Condition\"])\n",
    "df_weather.to_csv(\"weather.csv\", index=False)\n",
    "print(\"Scraping complete! Saved as weather.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
